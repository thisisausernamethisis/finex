# Prometheus Rules for Finex Bot
# These rules define alerting conditions for monitoring the application

groups:
  - name: finex-dlq
    rules:
      - alert: HighDLQDepth
        expr: finex_dlq_size > 10
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "High DLQ depth detected"
          description: "Dead Letter Queue {{ $labels.queue_name }} has {{ $value }} messages pending processing"

      - alert: CriticalDLQDepth
        expr: finex_dlq_size > 50
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Critical DLQ depth detected"
          description: "Dead Letter Queue {{ $labels.queue_name }} has reached critical depth with {{ $value }} messages"

      - alert: IncreasedDLQMessages
        expr: rate(finex_dlq_processed_total{outcome="failed"}[15m]) > 5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Increasing DLQ failures"
          description: "Queue {{ $labels.queue_name }} is experiencing increased failed message rate"

  - name: worker_alerts
    rules:
      - alert: HighFailureRate
        expr: rate(bullmq_failed_total[5m]) / (rate(bullmq_completed_total[5m]) + rate(bullmq_failed_total[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High job failure rate"
          description: "Queue {{ $labels.queue }} has a job failure rate over 10%."

      - alert: QueueBacklog
        expr: bullmq_waiting > 100
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Large queue backlog"
          description: "Queue {{ $labels.queue }} has more than 100 waiting jobs."

      - alert: StuckJobs
        expr: bullmq_active > 0 and time() - bullmq_active_timestamp > 600
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Jobs stuck in active state"
          description: "Queue {{ $labels.queue }} has jobs that have been active for more than 10 minutes."

  - name: database_alerts
    rules:
      - alert: DatabaseConnections
        expr: pg_stat_activity_count > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connection count"
          description: "Database has more than 10 active connections for more than 5 minutes."

      - alert: SlowQueries
        expr: pg_stat_activity_max_tx_duration{datname="finex"} > 30
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Slow database queries detected"
          description: "Queries in database finex are taking more than 30 seconds."

  - name: api_alerts
    rules:
      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) > 0.05
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "High API error rate"
          description: "Error rate is over 5% for the API endpoints."

      - alert: LongResponseTime
        expr: http_request_duration_seconds{quantile="0.95"} > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Long API response times"
          description: "95th percentile response time is over 1 second."

      - alert: RateLimitExceeded
        expr: rate(http_rate_limit_exceeded_total[5m]) > 10
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Rate limit frequently exceeded"
          description: "API rate limits are being exceeded frequently, possible abuse."
  
  - name: ai_alerts
    rules:
      - alert: HighOpenAICost
        expr: sum(increase(openai_tokens_total[24h]) * on(model) group_left openai_token_cost_per_1k) / 1000 > 10
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "High OpenAI API cost"
          description: "OpenAI API cost has exceeded $10 in the past 24 hours."

      - alert: LowRAGPerformance
        expr: rag_precision < 0.7 or rag_recall < 0.7
        for: 1d
        labels:
          severity: warning
        annotations:
          summary: "Low RAG performance"
          description: "RAG precision or recall has fallen below acceptable thresholds."
